#5. A university examination cell wants an AI assistant to generate academic content. Using GPT-2:
# Generate an exam notification for students
# Generate a short inspirational message for final-year students
# Summarize a given academic paragraph

!pip install transformers torch -q

from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

# GPT-2 text generation
generator = pipeline("text-generation", model="gpt2")

print("Exam Notification:")
print(generator("Write a short exam notification for students",max_new_tokens=50)[0]["generated_text"])

print("\nInspirational Message:")
print(generator("Write a short inspirational message for final year students:",max_new_tokens=40)[0]["generated_text"])

paragraph = """
Machine learning is a branch of artificial intelligence that focuses on building
systems capable of learning from data and improving their performance over time.
These systems are widely used in healthcare, finance, education and transportation.
By identifying patterns in large datasets, machine learning models help in decision
making, prediction and automation of complex processes.
"""

# Summarization
# Explicitly load the BART model and tokenizer to bypass the pipeline task recognition issue.
model_name = "facebook/bart-large-cnn"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Encode the input text
inputs = tokenizer.encode(paragraph, return_tensors="pt", max_length=1024, truncation=True)

# Generate summary IDs
summary_ids = model.generate(inputs,max_length=40,min_length=15,do_sample=False)

# Decode the summary IDs to text
summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

print("\n------ Summary ------\n")
print(summary_text)
